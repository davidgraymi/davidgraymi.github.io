{
 "cells": [
  {
   "source": [
    "\"\"\"\n",
    "Program: hw3.ipynb\n",
    "Author: David Gray\n",
    "Description: Homework 3: A KNN algorithm that uses Euclidean distance and weighted voting via an inverse function of distance to classify objects.\n",
    "Extra Credit: Functions available for finding the optimal k-value efficiently.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseFunction(x):\n",
    "    # Returns the inverse of x\n",
    "    return 1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p, q):\n",
    "    # Returns the Euclidean distance between two points\n",
    "    distance = 0\n",
    "    for i in range(1,len(p)):\n",
    "        distance += (p[i]-q[i])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(D, k, t):\n",
    "    # Returns the k nearest neighbors\n",
    "    neighbors = []\n",
    "    total = len(D)\n",
    "    for index in range(total):\n",
    "        d = D.loc[index]\n",
    "        dist = distance(t,d)\n",
    "        if len(neighbors) < k:\n",
    "            neighbors.append({'obj':d, 'distance':dist})\n",
    "        elif [dist < neighbor['distance'] for neighbor in neighbors]:\n",
    "            # Replace the neighbor that has the greatest distance from t with d\n",
    "            distance_array = np.array([n['distance'] for n in neighbors])\n",
    "            farthest = distance_array.max()\n",
    "            for i in range(len(neighbors)):\n",
    "                if distance_array[i] == farthest:\n",
    "                    far_n = i\n",
    "            neighbors[far_n] = {'obj':d, 'distance':dist}\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedVote(neighbors, t):\n",
    "    # Returns the predicted classification based on weighted votes of nearests neighbors\n",
    "#     distances = np.array([neighbor['distance'] for neighbor in neighbors])\n",
    "#     div = distances.max()\n",
    "    for neighbor in neighbors:\n",
    "        # Compare using percents\n",
    "#         neighbor['weight'] = abs((div - neighbor['distance'])/div)+1\n",
    "        # Compare distance with 1/x\n",
    "        neighbor['weight'] = inverseFunction(neighbor['distance'])\n",
    "    cls_and_distance = pd.DataFrame([{'class':neighbor['obj'].loc['label'],'weight':neighbor['weight']} for neighbor in neighbors])\n",
    "    weight_sums = cls_and_distance['weight'].groupby(cls_and_distance['class']).sum()\n",
    "    max_vote = weight_sums.max()\n",
    "    class_vote = weight_sums[weight_sums == max_vote].keys()[0]\n",
    "    return class_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(D, k, t):\n",
    "    # KNN algorithm\n",
    "    neighbors = getNeighbors(D, k, t)\n",
    "    predicted_class = weightedVote(neighbors, t)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicClassification():\n",
    "    # Classification using KNN\n",
    "    train_dataset = pd.read_csv(\"MNIST_train.csv\")\n",
    "    test_dataset = pd.read_csv(\"MNIST_test.csv\")\n",
    "    k=5\n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    print(\"k =\", k)\n",
    "    for index in range(len(test_dataset)):\n",
    "        obj = test_dataset.loc[index]\n",
    "        actual_class = obj.loc['label']\n",
    "        predicted_class = KNN(train_dataset, k, obj)\n",
    "        print(\"Desired class:\",actual_class, \"-- Computed class: \", predicted_class)\n",
    "        sample_count += 1\n",
    "        if actual_class == predicted_class:\n",
    "            correct_count += 1\n",
    "    accuracy = (correct_count/sample_count)*100\n",
    "    print(\"Accuracy rate: \", accuracy, \"%\")\n",
    "    print(\"Number of missclassified test samples:\", sample_count-correct_count)\n",
    "    print(\"Total number of test samples:\", sample_count)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictClass(obj_model, k):\n",
    "    # Returns the predicted classification based on weighted votes of nearests neighbors\n",
    "    neighbors = obj_model[:k]\n",
    "    for n in neighbors:\n",
    "        n['weight'] = inverseFunction(n['distance'])\n",
    "    cls_and_distance = pd.DataFrame([{'class':neighbor['obj'].loc['label'],'weight':neighbor['weight']} for neighbor in neighbors])\n",
    "    weight_sums = cls_and_distance['weight'].groupby(cls_and_distance['class']).sum()\n",
    "    max_vote = weight_sums.max()\n",
    "    class_vote = weight_sums[weight_sums == max_vote].keys()[0]\n",
    "    return class_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifiedKNN(model, k):\n",
    "    # Classification using KNN where distances have already been calculated\n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    print(\"k =\", k)\n",
    "    for index in range(len(model)):\n",
    "        obj_model = model[index]\n",
    "        obj = obj_model[0]['obj']\n",
    "        actual_class = obj['label']\n",
    "        predicted_class = predictClass(obj_model[1:], k)\n",
    "        sample_count += 1\n",
    "        if actual_class == predicted_class:\n",
    "            correct_count += 1\n",
    "    accuracy = (correct_count/sample_count)*100\n",
    "    print(\"Accuracy rate: \", accuracy, \"%\")\n",
    "    print(\"Number of missclassified test samples:\", sample_count-correct_count)\n",
    "    print(\"Total number of test samples:\", sample_count)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortArray(array):\n",
    "    # Returns a sorted array\n",
    "    for i in range(2,len(array[1:])):\n",
    "        item_to_insert = array[i]\n",
    "        j = i - 1\n",
    "        while j >= 1 and array[j]['distance'] > item_to_insert['distance']:\n",
    "            array[j + 1] = array[j]\n",
    "            j -= 1\n",
    "        array[j + 1] = item_to_insert\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train_D, test_D):\n",
    "    # Calculates and stores distances based on KNN\n",
    "    complete_model = []\n",
    "    total = len(train_D)\n",
    "    for index_t in range(len(test_D)):\n",
    "        t = test_D.loc[index_t]\n",
    "        model_per_obj = []\n",
    "        model_per_obj.append({'obj':t})\n",
    "        for index_d in range(total):\n",
    "            d = train_D.loc[index_d]\n",
    "            dist = distance(t,d)\n",
    "            model_per_obj.append({'obj':d, 'distance':dist})\n",
    "        sort_model_per_obj = sortArray(model_per_obj)\n",
    "        complete_model.append(sort_model_per_obj)\n",
    "    return complete_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizedKClassification():\n",
    "    # Build model\n",
    "    train_dataset = pd.read_csv(\"MNIST_train.csv\")\n",
    "    test_dataset = pd.read_csv(\"MNIST_test.csv\")\n",
    "    model = build_model(train_dataset, test_dataset)\n",
    "    # Find optimized k-value\n",
    "    k_range = round(math.sqrt(len(train_dataset)))\n",
    "    if k_range%2 == 0:\n",
    "        k_range-=1\n",
    "    for K in range(1,k_range):\n",
    "        modifiedKNN(model, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "k = 5\n",
      "Desired class: 0 -- Computed class:  0\n",
      "Desired class: 0 -- Computed class:  0\n",
      "Desired class: 0 -- Computed class:  0\n",
      "Desired class: 0 -- Computed class:  0\n",
      "Desired class: 0 -- Computed class:  0\n",
      "Desired class: 1 -- Computed class:  1\n",
      "Desired class: 1 -- Computed class:  1\n",
      "Desired class: 1 -- Computed class:  1\n",
      "Desired class: 1 -- Computed class:  1\n",
      "Desired class: 1 -- Computed class:  1\n",
      "Desired class: 2 -- Computed class:  8\n",
      "Desired class: 2 -- Computed class:  2\n",
      "Desired class: 2 -- Computed class:  2\n",
      "Desired class: 2 -- Computed class:  6\n",
      "Desired class: 2 -- Computed class:  2\n",
      "Desired class: 3 -- Computed class:  9\n",
      "Desired class: 3 -- Computed class:  3\n",
      "Desired class: 3 -- Computed class:  3\n",
      "Desired class: 3 -- Computed class:  3\n",
      "Desired class: 3 -- Computed class:  3\n",
      "Desired class: 4 -- Computed class:  4\n",
      "Desired class: 4 -- Computed class:  4\n",
      "Desired class: 4 -- Computed class:  4\n",
      "Desired class: 4 -- Computed class:  4\n",
      "Desired class: 4 -- Computed class:  9\n",
      "Desired class: 5 -- Computed class:  5\n",
      "Desired class: 5 -- Computed class:  6\n",
      "Desired class: 5 -- Computed class:  5\n",
      "Desired class: 5 -- Computed class:  5\n",
      "Desired class: 5 -- Computed class:  5\n",
      "Desired class: 6 -- Computed class:  6\n",
      "Desired class: 6 -- Computed class:  6\n",
      "Desired class: 6 -- Computed class:  6\n",
      "Desired class: 6 -- Computed class:  6\n",
      "Desired class: 6 -- Computed class:  6\n",
      "Desired class: 7 -- Computed class:  7\n",
      "Desired class: 7 -- Computed class:  7\n",
      "Desired class: 7 -- Computed class:  7\n",
      "Desired class: 7 -- Computed class:  7\n",
      "Desired class: 7 -- Computed class:  7\n",
      "Desired class: 8 -- Computed class:  8\n",
      "Desired class: 8 -- Computed class:  8\n",
      "Desired class: 8 -- Computed class:  8\n",
      "Desired class: 8 -- Computed class:  3\n",
      "Desired class: 8 -- Computed class:  8\n",
      "Desired class: 9 -- Computed class:  9\n",
      "Desired class: 9 -- Computed class:  9\n",
      "Desired class: 9 -- Computed class:  9\n",
      "Desired class: 9 -- Computed class:  9\n",
      "Desired class: 9 -- Computed class:  9\n",
      "Accuracy rate:  88.0 %\n",
      "Number of missclassified test samples: 6\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 1\n",
      "Accuracy rate:  84.0 %\n",
      "Number of missclassified test samples: 8\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 2\n",
      "Accuracy rate:  84.0 %\n",
      "Number of missclassified test samples: 8\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 3\n",
      "Accuracy rate:  86.0 %\n",
      "Number of missclassified test samples: 7\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 4\n",
      "Accuracy rate:  86.0 %\n",
      "Number of missclassified test samples: 7\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 5\n",
      "Accuracy rate:  88.0 %\n",
      "Number of missclassified test samples: 6\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 6\n",
      "Accuracy rate:  88.0 %\n",
      "Number of missclassified test samples: 6\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 7\n",
      "Accuracy rate:  90.0 %\n",
      "Number of missclassified test samples: 5\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 8\n",
      "Accuracy rate:  88.0 %\n",
      "Number of missclassified test samples: 6\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 9\n",
      "Accuracy rate:  90.0 %\n",
      "Number of missclassified test samples: 5\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 10\n",
      "Accuracy rate:  88.0 %\n",
      "Number of missclassified test samples: 6\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 11\n",
      "Accuracy rate:  86.0 %\n",
      "Number of missclassified test samples: 7\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 12\n",
      "Accuracy rate:  84.0 %\n",
      "Number of missclassified test samples: 8\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 13\n",
      "Accuracy rate:  84.0 %\n",
      "Number of missclassified test samples: 8\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 14\n",
      "Accuracy rate:  84.0 %\n",
      "Number of missclassified test samples: 8\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 15\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 16\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 17\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 18\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 19\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 20\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 21\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 22\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 23\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 24\n",
      "Accuracy rate:  80.0 %\n",
      "Number of missclassified test samples: 10\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 25\n",
      "Accuracy rate:  80.0 %\n",
      "Number of missclassified test samples: 10\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 26\n",
      "Accuracy rate:  80.0 %\n",
      "Number of missclassified test samples: 10\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 27\n",
      "Accuracy rate:  82.0 %\n",
      "Number of missclassified test samples: 9\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 28\n",
      "Accuracy rate:  78.0 %\n",
      "Number of missclassified test samples: 11\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 29\n",
      "Accuracy rate:  78.0 %\n",
      "Number of missclassified test samples: 11\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n",
      "k = 30\n",
      "Accuracy rate:  76.0 %\n",
      "Number of missclassified test samples: 12\n",
      "Total number of test samples: 50\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"################### basicClassification() ###################\\n\")\n",
    "basicClassification()\n",
    "print(\"\\n################### optimizedKClassification() ###################\\n\")\n",
    "optimizedKClassification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}